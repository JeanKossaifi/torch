


<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="keywords" content="tensor learning, tensor decomposition, tensor factorization, tensor operations, deep learning, tensorly, pytorch, tensorization, machine learning">
        <meta name="description" content="TensorLy-Torch: Deep Tensor Learning in Python with TensorLy and PyTorch">

        
        <meta name="author" content="Jean Kossaifi">
        <title>TensorLy-Torch: Deep Tensor Learning</title>
        

        <link rel="apple-touch-icon" sizes="180x180" href="../_static/favicon/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="../_static/favicon/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="../_static/favicon/favicon-16x16.png">
        <link rel="manifest" href="../_static/favicon/site.webmanifest">
        <link rel="mask-icon" href="../_static/favicon/safari-pinned-tab.svg" color="#5bbad5">
        <link rel="shortcut icon" href="../_static/favicon/favicon.ico">
        <meta name="theme-color" content="#ffffff">

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="../_static/bulma.min.css" />
        <link rel="stylesheet" type="text/css" href="../_static/base.min.css" />
        <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

        
        

        
        

        <script async src="https://www.googletagmanager.com/gtag/js?id=G-RFGGEBX0FR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-RFGGEBX0FR');
</script>

    </head>

    <body>
        
        <nav class="navbar is-dark has-shadow top" id="top">
    <div class="navbar-brand">
        <!-- <a class="navbar-item navbar-title" href="../index.html">
            TensorLy-Torch
		</a> -->
        <a class="navbar-item navbar-logo" href="../index.html">
            <img src="../_static/tensorly-torch-logo.png" class="navbar-logo" alt="TensorLy-Torch" height=30>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="../index.html">
            <i class="fa fa-home" aria-hidden="true"></i>
        </a>

        <a class="navbar-item is-tab is-hidden-desktop" href="https://github.com/tensorly/torch" target="_blank">
            <span class="icon"><i class="fa fa-github"></i></span>
        </a>

		<span class="navbar-burger" data-target="NavbarMenu" >
			<span></span>
			<span></span>
			<span></span>
		</span>

    </div>

	<div id="NavbarMenu" class="navbar-menu">
		<div class="navbar-start">

			<a class="navbar-item" href="../install.html">
				Install
			</a>
			<a class="navbar-item" href="index.html">
				User Guide
			</a>
			<a class="navbar-item" href="../modules/api.html">
				API
			</a>
			
			<a class="navbar-item" href="../about.html">
				About Us
			</a>

		</div>

		<div class="navbar-end">
			<a class="navbar-item is-tab tooltip is-hidden-touch" href="../index.html">
				<i class="fa fa-home" aria-hidden="true"></i>
				<span class="tooltiptext">Home page</span>
			</a>

			<a class="navbar-item is-tab tooltip is-hidden-touch" href="https://github.com/tensorly/torch" target="_blank">
				<span class="tooltiptext">Open project on Github</span>
				<span class="icon"><i class="fa fa-github"></i></span>
			</a>

		</div>
    </div>
</nav>
 

        

            
        
        <div class="columns is-centered"><div class="column is-one-quarter is-hidden-mobile aside">
    <div class="sidebar" id="sidebar">
        
        <div class="search">
            <div class="search-title">
                Search in TensorLy-Torch
            </div>

            <script>
              (function() {
                var cx = '002285679029256671182:5tfqz3cvmm8';
                var gcse = document.createElement('script');
                gcse.type = 'text/javascript';
                gcse.async = true;
                gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(gcse, s);
              })();
            </script>
            <gcse:searchbox-only></gcse:searchbox-only>
            
        </div>

        <div class="toc">
        
        
        
        
            <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing tensorly-Torch</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User guide</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Tensor Regression Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#trl-in-tensorly-torch">TRL in TensorLy-Torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-trl">Random TRL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#from-a-linear-layer">From a Linear layer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="factorized_conv.html">Factorized Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorized_linear.html">Tensorized Linear Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_hooks.html">Tensor Hooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev_guide/index.html">Development guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Us</a></li>
</ul>

        
        
        </div>
        
    </div>
</div>

            
            <div class="column is-three-quarters main-column">
                <div class="content main-content">

                    

  <div class="section" id="tensor-regression-layers">
<h1>Tensor Regression Layers</h1>
<p>In deep neural networks, while convolutional layers map between
high-order activation tensors, the output is still obtained through
linear regression: first the activation is flattened before being passed
through linear layers.</p>
<p>This approach has several drawbacks:</p>
<ul class="simple">
<li>Linear regression discards topological (e.g.&nbsp;spatial) information.</li>
<li>Very large number of parameters
(product of the dimensions
of the input tensor times the size of the output)</li>
<li>Lack of robustness</li>
</ul>
<p>A Tensor Regression Layer (TRL) generalizes the concept of linear
regression to higher-order but alleviates the above issues. It allows to
preserve and leverage multi-linear structure while being parsimonious in
terms of number of parameters. The low-rank constraints also acts as an
implicit reguralization on the model, typically leading to better sample
efficiency and robustness.</p>
<a class="reference internal image-reference" href="../_images/TRL.png"><img alt="../_images/TRL.png" class="align-center" src="../_images/TRL.png" style="width: 800px;" /></a>
<div class="section" id="trl-in-tensorly-torch">
<h2>TRL in TensorLy-Torch</h2>
<p>Now, let’s see how to do this in code with TensorLy-Torch</p>
</div>
<div class="section" id="random-trl">
<h2>Random TRL</h2>
<p>Let’s first see how to create and train a TRL from scratch</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tltorch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trl</span> <span class="o">=</span> <span class="n">tltorch</span><span class="o">.</span><span class="n">TuckerTRL</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">trl</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="from-a-linear-layer">
<h2>From a Linear layer</h2>
<p>You can also train a TRL from a Linear layer, by learning the pooling as
part of the TRL. Imagine you have an exciting blog with a flattening
layer followed by fully-connected layer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">out_features</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">spatial_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">in_rank</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">out_rank</span> <span class="o">=</span> <span class="mi">12</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pooling</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pooling</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
</pre></div>
</div>
<p>You can replace this block with a TRL that will initially return
approximately the same result:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trl</span> <span class="o">=</span> <span class="n">tltorch</span><span class="o">.</span><span class="n">TuckerTRL</span><span class="p">((</span><span class="n">in_features</span><span class="p">,</span> <span class="n">spatial_size</span><span class="p">,</span> <span class="n">spatial_size</span><span class="p">),</span> <span class="c1"># input shape</span>
                <span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="p">),</span> <span class="c1"># output shape</span>
                <span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span><span class="p">),</span><span class="c1">#full rank</span>
                <span class="n">project_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># More efficient computation</span>
<span class="n">trl</span><span class="o">.</span><span class="n">init_from_linear</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">pooling_modes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>Let’s try it with some dummy data. We first create a random batch of 3D
samples (with each <code class="docutils literal notranslate"><span class="pre">in_features</span></code> channel and spatial size
<code class="docutils literal notranslate"><span class="pre">spatial_size</span> <span class="pre">x</span> <span class="pre">spatial_size</span></code>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">spatial_size</span><span class="p">,</span> <span class="n">spatial_size</span><span class="p">))</span>
</pre></div>
</div>
<p>We can pass the data through our flattening block…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">res_block</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>and through our TRL</p>
<p>res_trl = trl(data)</p>
<p>Let’s now print the result</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">res_block</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1229</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1147</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1640</span><span class="p">,</span>  <span class="mf">0.1309</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1184</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0184</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1059</span><span class="p">,</span>  <span class="mf">0.0704</span><span class="p">,</span>
          <span class="mf">0.0293</span><span class="p">,</span>  <span class="mf">0.1542</span><span class="p">,</span>  <span class="mf">0.0767</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0413</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0451</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0278</span><span class="p">,</span>  <span class="mf">0.1947</span><span class="p">,</span>  <span class="mf">0.0358</span><span class="p">,</span>  <span class="mf">0.0316</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0535</span><span class="p">,</span>  <span class="mf">0.1365</span><span class="p">,</span>  <span class="mf">0.0663</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1503</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0498</span><span class="p">,</span>  <span class="mf">0.0643</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2299</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">MmBackward</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">res_trl</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.1229</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1147</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1640</span><span class="p">,</span>  <span class="mf">0.1309</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1184</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0184</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1059</span><span class="p">,</span>  <span class="mf">0.0704</span><span class="p">,</span>
          <span class="mf">0.0293</span><span class="p">,</span>  <span class="mf">0.1542</span><span class="p">,</span>  <span class="mf">0.0767</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0413</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0451</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0278</span><span class="p">,</span>  <span class="mf">0.1947</span><span class="p">,</span>  <span class="mf">0.0358</span><span class="p">,</span>  <span class="mf">0.0316</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0535</span><span class="p">,</span>  <span class="mf">0.1365</span><span class="p">,</span>  <span class="mf">0.0663</span><span class="p">,</span>
         <span class="o">-</span><span class="mf">0.1503</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0498</span><span class="p">,</span>  <span class="mf">0.0643</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2299</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">ViewBackward</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, they are pretty much the same!</p>
<p>Let’s verify that:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorly</span> <span class="kn">import</span> <span class="n">testing</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">res_trl</span><span class="p">,</span> <span class="n">res_block</span><span class="p">,</span> <span class="n">decimal</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>




                    <nav class="pagination">
    
    
    <a class="button is-medium pagination-previous" href="index.html" title="User guide" accesskey="p">
        <span class="icon">
            <i class="fa fa-arrow-circle-left"></i>
        </span>
        <span>Previous</span>
    </a>
    
    
    <a class="button is-medium pagination-next" href="factorized_conv.html" title="Factorized Convolutional Layers" accesskey="n">
        <span>Next </span>
        <span class="icon">
            <i class="fa fa-arrow-circle-right"></i>
        </span>
    </a>
    
</nav>

                </div>

                <footer class="footer">
    <div class="container has-text-centered">

        <p>
                &copy; 2020, Jean Kossaifi.
        </p>
            Built with <a href="http://sphinx-doc.org/">Sphinx</a> using the <a href="https://github.com/tensorly/tensorly">TensorLy</a> theme. 
    </div>
</footer>
            </div>
        </div>

        
        
        

        

        <script src="../_static/navigation.min.js"></script>

    </body>
</html>